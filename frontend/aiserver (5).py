# -*- coding: utf-8 -*-
"""AiServer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qb_0C49jiMjvjU_hguSn0MynDrqJ0m_V
"""

# âœ… Step 1. í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (ì¤‘ë³µ ì—†ì´ í•œ ë²ˆë§Œ)
!pip install scikit-learn==1.5.0 lightgbm fastapi uvicorn nest_asyncio pyngrok joblib optuna openai
!ngrok config add-authtoken 2wRlFfu3fZMabUEXJpLOYXQNbUK_3jakPRTomUDEKRj9FiHjB

# âœ… Step 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ import
import os
import numpy as np
import pandas as pd
import joblib
import optuna
import threading
import uvicorn
import nest_asyncio
from fastapi import FastAPI, APIRouter, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from pyngrok import ngrok
from lightgbm import LGBMClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from openai import OpenAI
import json
from pydantic import BaseModel
from sklearn.cluster import KMeans
from collections import Counter
import random
from pydantic import BaseModel
from typing import List


# âœ… Colab í™˜ê²½ì—ì„œ ì¤‘ì²© ì´ë²¤íŠ¸ ë£¨í”„ í—ˆìš©
nest_asyncio.apply()

# âœ… FastAPI ì•± ìƒì„±
app = FastAPI()

# âœ… CORS í—ˆìš© (ëª¨ë“  ë„ë©”ì¸ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ê²Œ)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# âœ… ë¼ìš°í„° ìƒì„±
router = APIRouter()

# âœ… OpenAI í´ë¼ì´ì–¸íŠ¸

client = OpenAI(api_key="")

"""ìš´ë™ì¶”ì²œ api

ì¸ê¸° ìš´ë™ api
"""

# âœ… 1. ìš´ë™ í´ë˜ìŠ¤ì™€ ê·œì¹™ ì •ì˜
classes = [
    "ì˜ì ìŠ¤ì¿¼íŠ¸", "ë°œë ë“¤ê¸°", "ë’¤ê¿ˆì¹˜ ë“¤ê¸°", "ë²„ë“œë…", "ë²½ ì§šê³  í”Œë­í¬",
    "ì‚¬ì´ë“œ ìŠ¤í…", "ì„œì„œ í•˜ëŠ” íŠ¸ìœ„ìŠ¤íŠ¸", "ìŠ¤íƒ ë”© ì‚¬ì´ë“œ ë ˆê·¸ ë¦¬í”„íŠ¸",
    "ìŠ¤íƒ ë”© í™ ìµìŠ¤í…ì…˜", "ì‹±ê¸€ ë ˆê·¸ ìŠ¤íƒ ë”©", "ì–´ê¹¨ ìŠ¤íŠ¸ë ˆì¹­",
    "ì œìë¦¬ ê±·ê¸°", "ì¢…ì•„ë¦¬ ìŠ¤íŠ¸ë ˆì¹­", "ì¢Œìš° ìŠ¤íƒ ë”© í¬ëŸ°ì¹˜", "í—ˆë¦¬ íšŒì „ ìŠ¤íŠ¸ë ˆì¹­"
]

focus_area_map = {"í•˜ì²´": 0, "ì½”ì–´": 1, "ì „ì‹ ": 2, "ìœ ì—°ì„±": 3, "ê· í˜•": 4}
label_rules = {
    "ì˜ì ìŠ¤ì¿¼íŠ¸":            {"score": (40, 60), "age": (65, 80), "condition": 0, "focus": "í•˜ì²´"},
    "ë°œë ë“¤ê¸°":             {"score": (30, 50), "age": (70, 80), "condition": 0, "focus": "í•˜ì²´"},
    "ë’¤ê¿ˆì¹˜ ë“¤ê¸°":           {"score": (40, 55), "age": (65, 80), "condition": 0, "focus": "í•˜ì²´"},
    "ë²„ë“œë…":               {"score": (75, 90), "age": (50, 65), "condition": 2, "focus": "ì½”ì–´"},
    "ë²½ ì§šê³  í”Œë­í¬":        {"score": (80, 95), "age": (50, 60), "condition": 2, "focus": "ì½”ì–´"},
    "ì‚¬ì´ë“œ ìŠ¤í…":          {"score": (60, 80), "age": (55, 70), "condition": 1, "focus": "ì „ì‹ "},
    "ì„œì„œ í•˜ëŠ” íŠ¸ìœ„ìŠ¤íŠ¸":     {"score": (50, 70), "age": (60, 75), "condition": 1, "focus": "ì½”ì–´"},
    "ìŠ¤íƒ ë”© ì‚¬ì´ë“œ ë ˆê·¸ ë¦¬í”„íŠ¸": {"score": (45, 65), "age": (50, 70), "condition": 1, "focus": "í•˜ì²´"},
    "ìŠ¤íƒ ë”© í™ ìµìŠ¤í…ì…˜":     {"score": (45, 65), "age": (55, 75), "condition": 1, "focus": "í•˜ì²´"},
    "ì‹±ê¸€ ë ˆê·¸ ìŠ¤íƒ ë”©":       {"score": (85, 100), "age": (50, 60), "condition": 2, "focus": "ê· í˜•"},
    "ì–´ê¹¨ ìŠ¤íŠ¸ë ˆì¹­":         {"score": (30, 50), "age": (65, 80), "condition": 0, "focus": "ìœ ì—°ì„±"},
    "ì œìë¦¬ ê±·ê¸°":           {"score": (50, 65), "age": (60, 75), "condition": 1, "focus": "ì „ì‹ "},
    "ì¢…ì•„ë¦¬ ìŠ¤íŠ¸ë ˆì¹­":       {"score": (40, 55), "age": (65, 80), "condition": 0, "focus": "ìœ ì—°ì„±"},
    "ì¢Œìš° ìŠ¤íƒ ë”© í¬ëŸ°ì¹˜":     {"score": (55, 75), "age": (55, 70), "condition": 1, "focus": "ì½”ì–´"},
    "í—ˆë¦¬ íšŒì „ ìŠ¤íŠ¸ë ˆì¹­":     {"score": (45, 65), "age": (65, 80), "condition": 0, "focus": "ìœ ì—°ì„±"},
}

# âœ… 2. ë°ì´í„° ìƒì„±
samples_per_class = 333
records = []
for label in classes:
    rule = label_rules[label]
    for _ in range(samples_per_class):
        left, right = np.random.randint(*rule["score"], size=2)
        age = np.random.randint(*rule["age"])
        gender = np.random.randint(0, 2)
        condition = rule["condition"]
        focus_area_code = focus_area_map[rule["focus"]]

        balance_diff = left - right
        recent_scores = [left + np.random.randint(-5, 5) for _ in range(3)]
        recent_avg = np.mean(recent_scores)
        recent_var = np.var(recent_scores)
        last_week_intensity = np.random.uniform(0.5, 1.0)
        last_week_duration = np.random.randint(20, 90)

        records.append([
            left, right, age, gender, condition,
            balance_diff, recent_avg, recent_var,
            last_week_intensity, last_week_duration,
            focus_area_code, label
        ])

data = pd.DataFrame(records, columns=[
    "balance_score_left", "balance_score_right", "age", "gender", "condition_encoded",
    "balance_diff", "recent_avg_score", "score_variance",
    "last_week_intensity", "last_week_duration", "focus_area_code", "label"
])

# âœ… 3. ë¼ë²¨ ì¸ì½”ë”© ë° í•™ìŠµ
le_label = LabelEncoder()
data["label_encoded"] = le_label.fit_transform(data["label"])
X = data.drop(columns=["label", "label_encoded"])
y = data["label_encoded"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

'''

# âœ… 4. Optuna íŠœë‹

def objective(trial):
    params = {
        "objective": "multiclass",
        "num_class": len(np.unique(y)),
        "metric": "multi_logloss",
        "verbosity": -1,
        "boosting_type": "gbdt",
        "learning_rate": trial.suggest_float("learning_rate", 0.01, 0.3),
        "num_leaves": trial.suggest_int("num_leaves", 20, 100),
        "max_depth": trial.suggest_int("max_depth", 3, 12),
        "min_child_samples": trial.suggest_int("min_child_samples", 10, 100),
        "min_gain_to_split": trial.suggest_float("min_gain_to_split", 0.0, 1.0),
        "subsample": trial.suggest_float("subsample", 0.6, 1.0),
        "colsample_bytree": trial.suggest_float("colsample_bytree", 0.6, 1.0),
        "n_estimators": trial.suggest_int("n_estimators", 100, 500),
    }
    model = LGBMClassifier(**params)
    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    acc = accuracy_score(y_test, preds)
    print(f"Accuracy: {acc:.4f}")
    return acc

study = optuna.create_study(direction="maximize")
study.optimize(objective, n_trials=10)

best_params = study.best_params
best_params["objective"] = "multiclass"
best_params["num_class"] = len(np.unique(y))
model = LGBMClassifier(**best_params)
model.fit(X_train, y_train)

joblib.dump(model, "lightgbm_best_model.pkl")
joblib.dump(le_label, "label_encoder.pkl")
'''
model = joblib.load("lightgbm_best_model.pkl")
le_label = joblib.load("label_encoder.pkl")
from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, confusion_matrix

# í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡
y_pred = model.predict(X_test)

# ì •í™•ë„
acc = accuracy_score(y_test, y_pred)
print(f"\nğŸ¯ ì •í™•ë„ (Accuracy): {acc:.4f}")

# ì •ë°€ë„, ì¬í˜„ìœ¨, F1
precision = precision_score(y_test, y_pred, average='macro', zero_division=0)
recall = recall_score(y_test, y_pred, average='macro', zero_division=0)
f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)

print(f"ğŸ“Š ì •ë°€ë„ (Precision): {precision:.4f}")
print(f"ğŸ“Š ì¬í˜„ìœ¨ (Recall): {recall:.4f}")
print(f"ğŸ“Š F1 ì ìˆ˜ (F1-score): {f1:.4f}")

# ìƒì„¸ ë¶„ë¥˜ ë¦¬í¬íŠ¸
print("\nğŸ“‹ [ë¶„ë¥˜ ë¦¬í¬íŠ¸]")
print(classification_report(y_test, y_pred, target_names=le_label.classes_, zero_division=0))

# confusion matrix (ì˜µì…˜)
cm = confusion_matrix(y_test, y_pred)
print("\nğŸ§© Confusion Matrix:")
print(cm)




### FastAPi ì„œë²„

class RecommendationRequest(BaseModel):
    balance_score_left: int
    balance_score_right: int
    age: int
    gender: int
    condition: str
    recent_scores: list[int]
    recent_intensity_avg: float
    recent_duration_sum: int
    focus_area: str

@router.post("/api/recommend")
def recommend(req: RecommendationRequest):
    condition_map = {"ë‚˜ì¨": 0, "ë³´í†µ": 1, "ì¢‹ìŒ": 2}
    focus_area_map = {"í•˜ì²´": 0, "ì½”ì–´": 1, "ì „ì‹ ": 2, "ìœ ì—°ì„±": 3, "ê· í˜•": 4}

    condition_encoded = condition_map.get(req.condition, 1)
    focus_area_code = focus_area_map.get(req.focus_area, 2)

    balance_diff = req.balance_score_left - req.balance_score_right
    recent_avg = np.mean(req.recent_scores)
    recent_var = np.var(req.recent_scores)

    X_input = pd.DataFrame([[
        req.balance_score_left, req.balance_score_right, req.age, req.gender,
        condition_encoded, balance_diff, recent_avg, recent_var,
        req.recent_intensity_avg, req.recent_duration_sum, focus_area_code
    ]], columns=X.columns)

    probs = model.predict_proba(X_input)[0]
    top3 = probs.argsort()[-3:][::-1]
    return {
        "status": "success",
        "recommendations": [{"name": le_label.inverse_transform([i])[0]} for i in top3]
    }



#Popular ìš´ë™
classes = [
    "ì˜ì ìŠ¤ì¿¼íŠ¸", "ë°œë ë“¤ê¸°", "ë’¤ê¿ˆì¹˜ ë“¤ê¸°", "ë²„ë“œë…", "ë²½ ì§šê³  í”Œë­í¬",
    "ì‚¬ì´ë“œ ìŠ¤í…", "ì„œì„œ í•˜ëŠ” íŠ¸ìœ„ìŠ¤íŠ¸", "ìŠ¤íƒ ë”© ì‚¬ì´ë“œ ë ˆê·¸ ë¦¬í”„íŠ¸",
    "ìŠ¤íƒ ë”© í™ ìµìŠ¤í…ì…˜", "ì‹±ê¸€ ë ˆê·¸ ìŠ¤í…ë”©", "ì–´ê¹¨ ìŠ¤íŠ¸ë ˆì¹­",
    "ì œìë¦¬ ê±·ê¸°", "ì¢…ì•„ë¦¬ ìŠ¤íŠ¸ë ˆì¹­", "ì¢Œìš° ìŠ¤í…ë”© í¬ëŸ°ì¹˜", "í—ˆë¦¬ íšŒì „ ìŠ¤íŠ¸ë ˆì¹­"
]

label_rules = {
    "ì˜ì ìŠ¤ì¿¼íŠ¸": {"score": (40, 60), "age": (65, 80)},
    "ë°œë ë“¤ê¸°": {"score": (30, 50), "age": (70, 80)},
    "ë’¤ê¿ˆì¹˜ ë“¤ê¸°": {"score": (40, 55), "age": (65, 80)},
    "ë²„ë“œë…": {"score": (75, 90), "age": (50, 65)},
    "ë²½ ì§šê³  í”Œë­í¬": {"score": (80, 95), "age": (50, 60)},
    "ì‚¬ì´ë“œ ìŠ¤í…": {"score": (60, 80), "age": (55, 70)},
    "ì„œì„œ í•˜ëŠ” íŠ¸ìœ„ìŠ¤íŠ¸": {"score": (50, 70), "age": (60, 75)},
    "ìŠ¤íƒ ë”© ì‚¬ì´ë“œ ë ˆê·¸ ë¦¬í”„íŠ¸": {"score": (45, 65), "age": (50, 70)},
    "ìŠ¤íƒ ë”© í™ ìµìŠ¤í…ì…˜": {"score": (45, 65), "age": (55, 75)},
    "ì‹±ê¸€ ë ˆê·¸ ìŠ¤í…ë”©": {"score": (85, 100), "age": (50, 60)},
    "ì–´ê¹¨ ìŠ¤íŠ¸ë ˆì¹­": {"score": (30, 50), "age": (65, 80)},
    "ì œìë¦¬ ê±·ê¸°": {"score": (50, 65), "age": (60, 75)},
    "ì¢…ì•„ë¦¬ ìŠ¤íŠ¸ë ˆì¹­": {"score": (40, 55), "age": (65, 80)},
    "ì¢Œìš° ìŠ¤í…ë”© í¬ëŸ°ì¹˜": {"score": (55, 75), "age": (55, 70)},
    "í—ˆë¦¬ íšŒì „ ìŠ¤íŠ¸ë ˆì¹­": {"score": (45, 65), "age": (65, 80)}
}

class PopularRequest(BaseModel):
    id: int
    score: float  # í‰ê·  ì¢Œìš° ì ìˆ˜
    age: int
    gender: int  # 0: ë‚¨ì„±, 1: ì—¬ì„±
    recent_scores: List[int]
    recent_intensity_avg: float
    recent_duration_sum: int
    focus_area: str   # ìœ ì €ê°€ ì£¼ë¡œ í•œ ìš´ë™ ë¶€ìœ„
    weeklyWorkoutCount: int
    history: List[str]   #ì§„í–‰í–ˆë˜ ìš´ë™

def generate_users(n=150):
    data = []
    for i in range(n):
        label = random.choice(classes)
        rule = label_rules[label]
        age = random.randint(*rule["age"])
        score = random.uniform(*rule["score"])
        gender = random.choice([0, 1])  # intë¡œ ë°”ê¿”ì•¼ í•¨

        count = random.randint(1, 5)
        data.append({
            "id": i,
            "age": age,
            "gender": gender,
            "balanceScore": score,
            "weeklyWorkoutCount": count,
            "history": [label]
        })
    return data

@router.post("/api/ai/popular")
def get_popular(req: PopularRequest):
    print("ğŸ“¥ ì¸ê¸° ìš´ë™ ìš”ì²­ ë°›ìŒ:", req.dict())
    users = generate_users()


    users.append({
    "id": req.id,
    "age": req.age,
    "gender": req.gender,
    "balanceScore": req.score,
    "weeklyWorkoutCount": req.weeklyWorkoutCount,
    "history": req.history,         # âœ… ì¶”ê°€
    "focus_area": req.focus_area,   # (í˜¹ì‹œ ì“¸ ìˆ˜ë„ ìˆìœ¼ë‹ˆ ê°™ì´ ì¶”ê°€)
})




    df = pd.DataFrame(users)
    features = df[["age", "gender", "balanceScore", "weeklyWorkoutCount"]]

    kmeans = KMeans(n_clusters=4, random_state=42).fit(features)
    df["cluster"] = kmeans.labels_

    my_cluster = df[df["id"] == req.id]["cluster"].values[0]
    same = df[df["cluster"] == my_cluster]

    all_focus_areas = []
    for h in same["history"]:
        all_focus_areas.extend(h)

    top = Counter(all_focus_areas).most_common(3)
    return {
        "status": "success",
        "cluster": int(my_cluster),
        "popularExercises": [{"name": name, "count": count} for name, count in top]
    }


#Projection


class ProjectionRequest(BaseModel):
    recentScores: List[int]


@router.post("/api/ai/projection")
async def predict_future_scores(data: ProjectionRequest):
    try:
        recent_scores = data.recentScores

        print("ğŸ“¥ projection ìš”ì²­ ë°›ìŒ:", recent_scores)

        if not recent_scores:
            return {"status": "error", "message": "recentScores ë¦¬ìŠ¤íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤."}

        prompt = f"""
ë‹¹ì‹ ì€ ìš´ë™ ê· í˜• ì ìˆ˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” AIì…ë‹ˆë‹¤.
ì•„ë˜ëŠ” ì‚¬ìš©ìì˜ ìµœê·¼ ì ìˆ˜ì…ë‹ˆë‹¤ (ì£¼ 1íšŒ ì¸¡ì • ê¸°ì¤€): {recent_scores}

ì´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í–¥í›„ 3ì£¼ê°„ì˜ ì˜ˆìƒ ì ìˆ˜ë¥¼ ì˜ˆì¸¡í•´ì£¼ì„¸ìš”.
ì ìˆ˜ ë²”ìœ„ëŠ” 0ë¶€í„° 100ê¹Œì§€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ ìš´ë™ì„ ì„±ì‹¤íˆ ìˆ˜í–‰í•œë‹¤ê³  ê°€ì •í•˜ì„¸ìš”.

ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ì˜ JSONìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
  "week1": float,
  "week2": float,
  "week3": float,
  "comment": "ê°„ë‹¨í•œ ì˜ˆì¸¡ ì½”ë©˜íŠ¸ (ì˜ˆ: ê¾¸ì¤€í•œ í›ˆë ¨ ì‹œ 3~4ì  í–¥ìƒì´ ê¸°ëŒ€ë©ë‹ˆë‹¤)"
}}
        """

        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.6,
            max_tokens=300,
        )

        raw_text = response.choices[0].message.content.strip()
        print("ğŸ§  GPT ì‘ë‹µ ì›ë¬¸:", raw_text)

        try:
            result = json.loads(raw_text)
        except json.JSONDecodeError:
            print("âŒ JSON íŒŒì‹± ì‹¤íŒ¨")
            return {
                "status": "error",
                "message": "GPT ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "raw": raw_text
            }

        print("âœ… projection íŒŒì‹± ì„±ê³µ:", result)
        return {"status": "success", "projection": result}

    except Exception as e:
        import traceback
        traceback.print_exc()
        return {"status": "error", "message": str(e)}



#Summary

class SummaryRequest(BaseModel):
    recentScores: List[int]
    leftScore: float
    rightScore: float
    percentile: int
    strongPart: str
    recommendedExercise: str


@router.post("/api/ai/summary")
async def generate_summary(data: SummaryRequest, mode: str = Query(default="natural")):
    try:
        recentScores = data.recentScores
        leftScore = data.leftScore
        rightScore = data.rightScore
        percentile = data.percentile
        strongPart = data.strongPart
        recommendedExercise = data.recommendedExercise

        if not recentScores or not isinstance(recentScores, list):
            return {"status": "error", "message": "recentScoresê°€ ë¹„ì–´ìˆê±°ë‚˜ ì˜ëª»ë¨"}

        # âœ… í”„ë¡¬í”„íŠ¸ ë¶„ê¸° ì²˜ë¦¬
        if mode == "list":
            prompt = f'''
ë‹¹ì‹ ì€ ê±´ê°• ì•±ì˜ ìš”ì•½ AIì…ë‹ˆë‹¤.

ë‹¤ìŒ ì •ë³´ë¥¼ í•­ëª©ë³„ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš” (ê° í•­ëª©ì€ ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„):

- ìµœê·¼ ì ìˆ˜ í‰ê· : {sum(recentScores)//len(recentScores)}ì 
- ë˜ë˜ ëŒ€ë¹„: ìƒìœ„ {percentile}%
- ì™¼ë°œ ì ìˆ˜: {leftScore}ì 
- ì˜¤ë¥¸ë°œ ì ìˆ˜: {rightScore}ì 
- í˜„ì¬ ë¶„ì„ ìš”ì•½: {"ì™¼ë°œ" if leftScore > rightScore else "ì˜¤ë¥¸ë°œ"} ê· í˜•ì´ ë” ë›°ì–´ë‚©ë‹ˆë‹¤.
- ì¶”ì²œ ìš´ë™: {recommendedExercise}
            '''.strip()
        else:
            prompt = f'''
ë‹¹ì‹ ì€ ê±´ê°• ì•±ì˜ ì¢…í•© ë¶„ì„ AIì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì •ë³´ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

- ìµœê·¼ ê· í˜• ì ìˆ˜: {recentScores}
- ì™¼ë°œ ì ìˆ˜: {leftScore}
- ì˜¤ë¥¸ë°œ ì ìˆ˜: {rightScore}
- ë˜ë˜ ëŒ€ë¹„ ìƒìœ„ {percentile}%
- í˜„ì¬ ê°•ì : {strongPart}
- í˜„ì¬ ì¶”ì²œ ìš´ë™: {recommendedExercise}

ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ìì—°ìŠ¤ëŸ½ê³  ê²©ë ¤ë˜ëŠ” ìš”ì•½ë¬¸ì„ 3ì¤„ ì´ë‚´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
            '''.strip()

        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ê±´ê°• ë°ì´í„°ë¥¼ ìš”ì•½í•˜ëŠ” ë¶„ì„ê°€ì•¼"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=300,
        )

        summary = response.choices[0].message.content
        print("âœ… summary ìƒì„± ì™„ë£Œ")
        return {"status": "success", "summary": summary}

    except Exception as e:
        import traceback
        traceback.print_exc()
        return {"status": "error", "message": str(e)}


app.include_router(router)


# âœ… Step 4. FastAPI ì„œë²„ ì‹¤í–‰
def run_server():
    uvicorn.run(app, host="0.0.0.0", port=8008)

thread = threading.Thread(target=run_server)
thread.start()


# âœ… Step 5. Public URL ë…¸ì¶œ (ngrok ì‚¬ìš©)
public_url = ngrok.connect(8008)
print(f"ğŸš€ Public API URL: {public_url}")

"""15ì¼ 23:29 í…ŒìŠ¤íŠ¸
api/popular ì‘ë™ x
api/summary ì‘ë™ x

"""
